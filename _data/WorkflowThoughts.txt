Workflows - Each Work flow has a dictionary
The workflows are the API

Workflow Outputs
- Create a new dataset
  - Create a new Workflow Dataset
  - Create a new Raw Dataset
- Create a new data node
  - Create Metadata
  - Create High Value Data
  - Create Data


Sensor Data are parent nodes that are independent of other datasets

Workflow Data are parent/child nodes that are dependent on other datasets
A Combo Dataset is a dataset that applies a workflow which ingests datasets and creates a new dataset.
A dataset is considered new when the metadata of the variables changes.  
i.e. In EBSD and nanoindentation, the relative position of the x,y locations are converted to 
absolute values through a workflow that performs alignment.

Inputs are posts with their hash.

A dataset is a graph with parent nodes and workflows applied to the parent nodes.  
Parents Nodes can either be 

A Workflow dictionary describes the input variables and the output variables.  The outputs 
can be directly output to simple-data-structure or hdf5-data-structure.  

Each time a change is made, the dictionary should be checked.

We learn a lot more about data through diverse metadata not when metadata stays static

Contents of a workflow
dict
Inputs
- native
- dset
Execution
Outputs
- native
  value
  location
Viz
- url
  title
  
  Types of workflows
  Raw
  Aggregate
  Spatial
  
  description